{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will walk through a simple example using the PDPA dataset to illustrate how you can fine-tune Golden Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.models import GoldenRetriever\n",
    "from src.encoders import USEEncoder\n",
    "from src.data_handler.kb_handler import kb, kb_handler\n",
    "from src.finetune.generators import hard_triplet_generator\n",
    "from src.finetune.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import .csv file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_string</th>\n",
       "      <th>processed_string</th>\n",
       "      <th>kb_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is personal data?</td>\n",
       "      <td>Organisations, General Personal data refers t...</td>\n",
       "      <td>pdpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the PDPA come into force?</td>\n",
       "      <td>Organisations, General The PDPA was implement...</td>\n",
       "      <td>pdpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the objectives of the PDPA?</td>\n",
       "      <td>Organisations, General The PDPA aims to safeg...</td>\n",
       "      <td>pdpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the PDPA benefit business?</td>\n",
       "      <td>Organisations, General The PDPA will strength...</td>\n",
       "      <td>pdpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How will the PDPA impact business costs?</td>\n",
       "      <td>Organisations, General The provisions of the ...</td>\n",
       "      <td>pdpa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query_string  \\\n",
       "0                    What is personal data?   \n",
       "1        When did the PDPA come into force?   \n",
       "2      What are the objectives of the PDPA?   \n",
       "3       How does the PDPA benefit business?   \n",
       "4  How will the PDPA impact business costs?   \n",
       "\n",
       "                                    processed_string kb_name  \n",
       "0   Organisations, General Personal data refers t...    pdpa  \n",
       "1   Organisations, General The PDPA was implement...    pdpa  \n",
       "2   Organisations, General The PDPA aims to safeg...    pdpa  \n",
       "3   Organisations, General The PDPA will strength...    pdpa  \n",
       "4   Organisations, General The provisions of the ...    pdpa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get df using kb_handler\n",
    "kbh = kb_handler()\n",
    "\n",
    "path_to_csv = \"./../../data/pdpa.csv\"\n",
    "answer_col = \"ans_str\"\n",
    "query_col = \"query_str\"\n",
    "context_col = \"\"\n",
    "kb_name = \"pdpa\"\n",
    "\n",
    "pdpa_kb = kbh.parse_csv(path_to_csv, answer_col, query_col, context_col, kb_name)\n",
    "pdpa_df = pdpa_kb.create_df()\n",
    "pdpa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "test_dict = dict()\n",
    "\n",
    "pdpa_id = pdpa_df.index.values\n",
    "train_idx, test_idx = train_test_split(pdpa_id, test_size=0.4, random_state=100)\n",
    "\n",
    "train_dict[\"pdpa\"] = train_idx\n",
    "test_dict[\"pdpa\"] = test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet loss is used for the fine-tuning process and for each step, we mine the hard triplets by finding an incorrect response that is the most similar to the query text. We noticed that using these hard triplets for fine-tuning improves the model performance significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\Kenneth\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n",
      "cost_mean_batch 0.29314637\n"
     ]
    }
   ],
   "source": [
    "use = USEEncoder()\n",
    "gr = GoldenRetriever(use)\n",
    "\n",
    "train_dataset_loader = hard_triplet_generator(pdpa_df, train_dict, gr, CONFIG)\n",
    "    \n",
    "for q, r, neg_r in train_dataset_loader:\n",
    "\n",
    "    cost_mean_batch = gr.finetune(\n",
    "        question=q, answer=r, context=r,\n",
    "        neg_answer=neg_r, neg_answer_context=neg_r,\n",
    "        margin=0.3, loss=\"triplet\"\n",
    "    )\n",
    "\n",
    "    print(\"cost_mean_batch\", cost_mean_batch)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = gr.encoder.encode(\"Why do we need PDPA?\", string_type=\"query\")\n",
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export finetuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./finetune_use\"\n",
    "os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_use\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_use\\assets\n"
     ]
    }
   ],
   "source": [
    "gr.export_encoder(save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Restore weights and ensure that that encoded texts are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n"
     ]
    }
   ],
   "source": [
    "use_res = USEEncoder()\n",
    "gr_res = GoldenRetriever(use_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n"
     ]
    }
   ],
   "source": [
    "gr_res.restore_encoder(save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text_res = gr_res.encoder.encode(\"Why do we need PDPA?\", string_type=\"query\")\n",
    "encoded_text_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that the export and restoration of weights for the encoder was successful given that the two vectorized responses `encoded_text` and `encoded_text_res` are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.assert_equal(\n",
    "    encoded_text, encoded_text_res, message=None, summarize=None, name=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:goldenre_fastapi] *",
   "language": "python",
   "name": "conda-env-goldenre_fastapi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
