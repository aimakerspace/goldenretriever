{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.models import GoldenRetriever\n",
    "from src.encoders import USEEncoder, ALBERTEncoder, BERTEncoder\n",
    "from src.data_handler.kb_handler import kb, kb_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "test_dict = dict()\n",
    "\n",
    "# Get df using kb_handler\n",
    "kbh = kb_handler()\n",
    "kbs = kbh.load_sql_kb(\n",
    "                      cnxn_path=\"./db_cnxn_str.txt\", \n",
    "                      kb_names=[\"nrf_virement\"])\n",
    "\n",
    "df = pd.concat([single_kb.create_df() for single_kb in kbs]).reset_index(drop='True')\n",
    "df = df.iloc[:10]\n",
    "kb_names = df['kb_name'].unique()\n",
    "\n",
    "for kb_name in kb_names:\n",
    "    kb_id = df[df['kb_name'] == \"nrf_virement\"].index.values\n",
    "    train_idx, test_idx = train_test_split(kb_id, test_size=0.4,\n",
    "                                        random_state=100)\n",
    "\n",
    "    train_dict[\"nrf_virement\"] = train_idx\n",
    "    test_dict[\"nrf_virement\"] = test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_hard_neg_ans(df, train_dict, model):\n",
    "    \"\"\"\n",
    "    Generates negative answer from dataframe by randomization\n",
    "    \n",
    "    Sample output:\n",
    "    --------------\n",
    "    {'PDPA': [array([ 95,  84,  42, 185, 187, 172, 145,  71,   5,  36,  43, 153,  70,\n",
    "                    140, 165,   0,  78, 162,  68, 184, 179,  30, 106,  13,  72,  17,\n",
    "                    18,  38, 109,  47, 113,  56,  27,  63, 147, 105, 121,   2,  80,\n",
    "                    182,  61,  49, 135, 193,  91,   4, 100, 141, 129, 159, 132, 108,\n",
    "                    155, 130,  86,  93, 137, 144,  58,  60, 107, 143, 194,  34,  14,\n",
    "                    66,  53,  98, 180,  94, 138, 176,  79,  87, 103,  67,  24,   8]),\n",
    "              array([141, 129, 155,   5, 108, 180,  63,   0, 143, 130,  98, 132,  61,\n",
    "                     103, 137,  13,  17,  71, 107, 144, 121,  68,  66, 184, 179, 135,\n",
    "                     113, 194,  58,  53, 193,  34,  42,  78,  60, 106, 182,  72, 172,\n",
    "                     145, 100, 176,  36, 159,  30,  14,  93,  43,  95,  79,   2,  87,\n",
    "                       8,  18, 147,  91,  49,   4,  70,  67,  84,  80,  27,  47,  38,\n",
    "                     138,  24, 187,  86, 153,  94, 140, 162, 109,  56, 105, 185, 165])],\n",
    "     'nrf': [array([214, 240, 234, 235, 326, 244, 226, 252, 317, 331, 259, 215, 333,\n",
    "                    318, 276, 267, 251, 329, 257, 261, 243, 245, 203, 337, 255, 287,\n",
    "                    315, 296, 279, 209, 197, 227, 200, 304, 223, 198, 282, 289, 205,\n",
    "                    319, 212, 254, 256, 303, 338, 230, 210, 262, 249, 294, 290, 275,\n",
    "                    283, 299, 263, 220, 204]),\n",
    "              array([249, 245, 331, 290, 254, 249, 249, 261, 296, 251, 214, 240, 275,\n",
    "                     294, 319, 337, 215, 197, 200, 257, 289, 203, 282, 252, 315, 317,\n",
    "                     230, 283, 304, 279, 333, 249, 299, 204, 318, 326, 262, 287, 256,\n",
    "                     234, 303, 235, 243, 276, 198, 338, 220, 329, 255, 209, 263, 267,\n",
    "                     210, 223, 259, 212, 205])]}\n",
    "    \"\"\"\n",
    "    train_dict_with_neg = {}\n",
    "    random.seed(42)\n",
    "\n",
    "    for kb, ans_pos_idxs in train_dict.items():\n",
    "        keys = []\n",
    "        train_df = df.loc[ans_pos_idxs]\n",
    "\n",
    "        # encodings of all possible answers\n",
    "        all_possible_answers_in_kb = train_df.processed_string.unique().tolist()\n",
    "        encoded_all_possible_answers_in_kb = model.predict(all_possible_answers_in_kb, string_type='response')\n",
    "\n",
    "        # encodings of train questions\n",
    "        train_questions = train_df.query_string\n",
    "        encoded_train_questions = model.predict(train_questions, string_type='query')\n",
    "\n",
    "        # get similarity matrix\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity_matrix = cosine_similarity(encoded_train_questions, encoded_all_possible_answers_in_kb)\n",
    "\n",
    "        # get index of correct answers, indexed according to unique answers\n",
    "        correct_answers = train_df.processed_string.tolist()\n",
    "        idx_of_correct_answers = [all_possible_answers_in_kb.index(correct_answer) for correct_answer in correct_answers]\n",
    "\n",
    "        # get second best answer index by kb_df\n",
    "        ans_neg_idxs = []\n",
    "        for idx_of_correct_answer, similarity_array in zip(idx_of_correct_answers, similarity_matrix):\n",
    "            similarity_array[idx_of_correct_answer] = -1\n",
    "            second_best_answer_idx_in_all_possible_answers = similarity_array.argmax()\n",
    "            second_best_answer_string = all_possible_answers_in_kb[second_best_answer_idx_in_all_possible_answers]\n",
    "            second_best_answer_idx_in_kb_df = train_df.loc[train_df.processed_string == second_best_answer_string].index[0]\n",
    "            ans_neg_idxs.append(second_best_answer_idx_in_kb_df)\n",
    "\n",
    "        # return a list of correct and close wrong answers\n",
    "        keys.append(ans_pos_idxs)\n",
    "        keys.append(np.array(ans_neg_idxs))\n",
    "        train_dict_with_neg[kb] = keys \n",
    "    \n",
    "    return train_dict_with_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(batch_size, query, response, neg_response, shuffle_data=False):\n",
    "    random.seed(42)\n",
    "    zip_list = list(zip(query,response,neg_response))\n",
    "\n",
    "    num_samples = len(query)\n",
    "    while True:\n",
    "        if shuffle_data:\n",
    "            random.shuffle(zip_list)\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            q_batch = [x[0] for x in zip_list[offset:offset+batch_size]]\n",
    "            r_batch = [x[1] for x in zip_list[offset:offset+batch_size]]\n",
    "            neg_r_batch = [x[2] for x in zip_list[offset:offset+batch_size]]\n",
    "        \n",
    "            yield(q_batch, r_batch, neg_r_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_triplet_generator(df, train_dict, model):\n",
    "    \"\"\"\n",
    "    Returns a generator that gives batches of training triplets\n",
    "    \"\"\"\n",
    "    train_dict_with_neg = _generate_hard_neg_ans(df, train_dict, model)\n",
    "    train_pos_idxs = np.concatenate([v[0] for k,v in train_dict_with_neg.items()], axis=0)\n",
    "    train_neg_idxs = np.concatenate([v[1] for k,v in train_dict_with_neg.items()], axis=0)\n",
    "\n",
    "    train_query = df.iloc[train_pos_idxs].query_string.tolist()\n",
    "    train_response = df.iloc[train_pos_idxs].processed_string.tolist()\n",
    "    train_neg_response = df.iloc[train_neg_idxs].processed_string.tolist()\n",
    "    \n",
    "    train_dataset_loader = gen(2, train_query, train_response, train_neg_response, shuffle_data=True)\n",
    "    \n",
    "    return train_dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_goldenretriever(encoder=None, save_dir=None, kbs=None,\n",
    "                         query_string=None, kb_name=None):\n",
    "\n",
    "    enc = encoder()\n",
    "    gr = GoldenRetriever(enc)\n",
    "\n",
    "    train_dataset_loader = hard_triplet_generator(df, train_dict, gr)\n",
    "    \n",
    "    for q, r, neg_r in train_dataset_loader:\n",
    "\n",
    "        cost_mean_batch = gr.finetune(question=q, answer=r, context=r, \\\n",
    "                                         neg_answer=neg_r, neg_answer_context=neg_r, \\\n",
    "                                         margin=0.3, loss=\"triplet\")\n",
    "        print(\"cost_mean_batch\", cost_mean_batch)\n",
    "\n",
    "        break\n",
    "        \n",
    "    encoded_text = gr.encoder.encode(\"Why is the sky blue?\", string_type=\"query\")\n",
    "    gr.export_encoder(save_dir=save_dir)\n",
    "    \n",
    "    enc_2 = encoder()\n",
    "    gr_2 = GoldenRetriever(enc_2)\n",
    "    gr_2.restore_encoder(save_dir=save_dir)\n",
    "    \n",
    "    gr_2.load_kb(kbs)\n",
    "    gr_2.make_query(query_string, kb_name=kb_name)\n",
    "    encoded_text_2 = gr_2.encoder.encode(\"Why is the sky blue?\", string_type=\"query\")\n",
    "    \n",
    "    print(\"encoded_text\", encoded_text)\n",
    "    print(\"encoded_text_2\", encoded_text_2)\n",
    "    \n",
    "    tf.debugging.assert_equal(\n",
    "    encoded_text, encoded_text_2, message=None, summarize=None, name=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"What are the requirements of debarring investigator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n",
      "cost_mean_batch 0.3\n",
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_use\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_use\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n",
      "model initiated!\n",
      "2020-05-14 20:06:23.759892 : kb loaded - nrf_virement \n",
      "encoded_text tf.Tensor(\n",
      "[[ 0.07713778 -0.01766009 -0.04501201 -0.04626905 -0.05282243 -0.026104\n",
      "   0.07056151  0.03558303 -0.05186373 -0.0064343   0.02678842 -0.08156374\n",
      "  -0.02875711 -0.03512157 -0.05726431 -0.00918735 -0.03882345  0.0346642\n",
      "  -0.02840316 -0.03403239 -0.01009876 -0.07093532 -0.00752224 -0.03060159\n",
      "  -0.03592576  0.01303794  0.05862886  0.0063034  -0.02272478  0.06184517\n",
      "   0.03744913 -0.00751562  0.00954572  0.11016147  0.02429915 -0.00077278\n",
      "   0.01034335  0.01482726 -0.06822246 -0.05939544  0.02190411  0.03945052\n",
      "  -0.04884628 -0.00552307  0.05113245  0.0342414   0.02333902 -0.01315226\n",
      "   0.01515451 -0.03625035 -0.06819116 -0.05765338 -0.05160503  0.04113428\n",
      "  -0.0154777   0.01416995 -0.07035542  0.06165114 -0.07420117  0.09438286\n",
      "   0.00774255 -0.04791952  0.09487133  0.06020354 -0.02937498  0.05366033\n",
      "  -0.05098031 -0.06611858 -0.05001807  0.00823597 -0.03199609 -0.01229879\n",
      "  -0.05123171 -0.04651342 -0.0089915   0.02571904 -0.041391   -0.03075121\n",
      "   0.00726541 -0.01450123 -0.0364918  -0.05215725 -0.05668604  0.03704308\n",
      "   0.04149637  0.05727961  0.01213237  0.04598372  0.0333932  -0.04876644\n",
      "  -0.02562891 -0.03463634 -0.0112821  -0.00972642  0.00692945 -0.01083127\n",
      "  -0.01650919  0.04496781  0.01224945  0.07662851 -0.04536317  0.07684816\n",
      "  -0.06829893  0.00660856  0.00746848  0.03824338 -0.00540722  0.01269146\n",
      "  -0.02400788  0.01390582 -0.02301105  0.00041156 -0.01012683  0.02523189\n",
      "  -0.012092    0.02592711  0.04693777 -0.06702039 -0.03724068 -0.04823183\n",
      "   0.04843681  0.01038774 -0.06336087 -0.0156668   0.04168632  0.00917922\n",
      "  -0.02069708 -0.0247115  -0.06107789 -0.00436255 -0.02700658 -0.02981561\n",
      "   0.02864637 -0.0449001   0.02461612 -0.00396248 -0.06094465  0.07641841\n",
      "  -0.01410442 -0.0253572   0.06064675  0.06061034 -0.06539125  0.0187633\n",
      "  -0.02146232 -0.08089294 -0.09690257 -0.02740385 -0.02020344  0.05780921\n",
      "  -0.05540393  0.05510009 -0.03332917 -0.07841402 -0.07878609  0.01146194\n",
      "   0.04123399 -0.05211356 -0.0582474  -0.06592244 -0.01313032  0.02678393\n",
      "  -0.05343274  0.00440662  0.053574   -0.0561483   0.02102838  0.03821297\n",
      "   0.02915834  0.00747701 -0.03651261 -0.01624576 -0.07474233  0.00650053\n",
      "   0.117842    0.02729447 -0.03053163  0.05341165  0.04454866  0.03931216\n",
      "   0.09956812  0.02452448  0.00883975  0.07133874  0.02985579 -0.03707941\n",
      "  -0.0434027   0.03549205  0.02058476  0.03808713  0.03933963  0.06698063\n",
      "   0.02990459 -0.01204948  0.00339209 -0.00960551  0.03788317  0.07059729\n",
      "  -0.01144606  0.01229244  0.08274607 -0.00732027 -0.05824679  0.10356169\n",
      "  -0.0094143   0.01588267  0.00167197  0.03159037  0.02479352 -0.01597543\n",
      "   0.03313017 -0.11997186  0.03024802 -0.01534616  0.00127044  0.06609464\n",
      "   0.02183471 -0.03870533 -0.01355305  0.0196354   0.05471844  0.03522392\n",
      "   0.00202838 -0.02855081 -0.0436471   0.01689846  0.03851288  0.01119246\n",
      "  -0.08929126 -0.01628174  0.01371785  0.02353508 -0.04625374  0.02600716\n",
      "   0.01393424  0.05441526  0.00615437 -0.02123166 -0.02383309  0.03009527\n",
      "   0.03507154 -0.08470742  0.07524072 -0.04900159 -0.03824297  0.02005625\n",
      "  -0.04827765 -0.03476966 -0.05669461  0.07462248  0.02860466 -0.03397477\n",
      "   0.02375467  0.0010452   0.00727962 -0.03291095  0.04327936 -0.04631392\n",
      "  -0.03558316 -0.02410508  0.06120874 -0.05615826 -0.08075131 -0.0137067\n",
      "  -0.00044124 -0.08104508  0.08530852 -0.07473116 -0.02352187  0.03188273\n",
      "  -0.01602949  0.02607873  0.03390785 -0.02008476 -0.02975241 -0.0302441\n",
      "  -0.07765332  0.00190004  0.0306004  -0.03319408 -0.02808125 -0.02818995\n",
      "  -0.07130712 -0.02210228 -0.06517854  0.01152103  0.04455154 -0.00785413\n",
      "  -0.01375183  0.03922431 -0.00474037  0.01261893  0.05405952 -0.05730643\n",
      "  -0.02695682  0.01536124 -0.00086421  0.01635651 -0.06255824 -0.03794855\n",
      "   0.03875137 -0.00511006  0.09627219 -0.02878522 -0.02432816 -0.08068776\n",
      "  -0.00526082 -0.0458064   0.01031234 -0.02698353 -0.06881353 -0.03558536\n",
      "   0.03405454 -0.09444208  0.00567452 -0.02744342  0.03458241 -0.03737978\n",
      "  -0.04397875  0.02560822  0.00722427 -0.01386164  0.03910863 -0.07955288\n",
      "   0.03376446  0.0303402  -0.02526729  0.06460379  0.06017378  0.02656833\n",
      "   0.000491    0.03874032  0.06629907 -0.07098213  0.04496467 -0.01898149\n",
      "   0.06656215 -0.0067992   0.01262479  0.03711055 -0.01604308 -0.04118203\n",
      "  -0.05387774 -0.0363503  -0.01390218 -0.0137256   0.02476459  0.05006815\n",
      "  -0.02730579 -0.01190232  0.0706568   0.01404586  0.01984414 -0.05409718\n",
      "  -0.02737833 -0.09573251 -0.02532179 -0.00193205  0.01844274 -0.04268635\n",
      "   0.06987672 -0.04131944  0.00438592  0.02850924  0.08211428 -0.03913155\n",
      "   0.00264381 -0.12220404 -0.0224926   0.059965   -0.03115409  0.07936425\n",
      "   0.01741082  0.02059508 -0.02845884  0.00627551  0.01968188 -0.02061144\n",
      "   0.01399168  0.00455417 -0.01095931 -0.02148769 -0.05967702 -0.07111817\n",
      "   0.05957249  0.01643533 -0.07622371 -0.07805865  0.0049861  -0.0179853\n",
      "  -0.07184526 -0.05129252 -0.07481048  0.00494767 -0.04115682  0.00959976\n",
      "   0.02060041  0.0539535   0.04293294  0.0162659   0.0809947  -0.03331964\n",
      "  -0.0117103   0.02815461 -0.08322152 -0.01593661  0.06004281  0.06888754\n",
      "   0.03986826 -0.05247298  0.02286522  0.04605852  0.01214583 -0.01620888\n",
      "   0.04491688  0.05243057 -0.06609563 -0.02674789 -0.06574447 -0.02983483\n",
      "  -0.03286179 -0.0341695  -0.0127625  -0.03432469 -0.03980097 -0.0369922\n",
      "   0.01653328 -0.02075193  0.02116952  0.03323997 -0.04755267 -0.00554903\n",
      "   0.05113972  0.02292646  0.03295898 -0.06207736  0.07380884 -0.06839673\n",
      "   0.06278647 -0.00615144  0.03377312 -0.05659176 -0.00696464  0.0442487\n",
      "  -0.01600138 -0.04408437  0.01939425 -0.0040339   0.01576127  0.03264733\n",
      "  -0.03385737 -0.03255405 -0.02746593  0.05273899  0.01850544  0.04152621\n",
      "  -0.06056116  0.00188016 -0.05293378  0.02977061  0.01565065  0.02585942\n",
      "  -0.01079602 -0.0251943  -0.04747934  0.00228073  0.06186875  0.05837283\n",
      "   0.00334668 -0.01386614 -0.00626584 -0.0074322   0.09155073  0.04740443\n",
      "  -0.02826038 -0.03493985  0.02874506 -0.00297582  0.08044478  0.08776549\n",
      "   0.01951958  0.07297342  0.06428444 -0.02805423 -0.02069601 -0.02491912\n",
      "   0.01416174  0.01735874  0.02523534  0.01916438  0.03095045  0.01848352\n",
      "  -0.06285969 -0.03973932  0.10712719 -0.06443982  0.00570433 -0.00882013\n",
      "  -0.01421769  0.03016425  0.08171633  0.03410171 -0.07964829 -0.06510738\n",
      "  -0.02805409  0.08474384  0.02522042  0.06854501 -0.00523394 -0.03939554\n",
      "   0.01020869  0.00400388]], shape=(1, 512), dtype=float32)\n",
      "encoded_text_2 tf.Tensor(\n",
      "[[ 0.07713778 -0.01766009 -0.04501201 -0.04626905 -0.05282243 -0.026104\n",
      "   0.07056151  0.03558303 -0.05186373 -0.0064343   0.02678842 -0.08156374\n",
      "  -0.02875711 -0.03512157 -0.05726431 -0.00918735 -0.03882345  0.0346642\n",
      "  -0.02840316 -0.03403239 -0.01009876 -0.07093532 -0.00752224 -0.03060159\n",
      "  -0.03592576  0.01303794  0.05862886  0.0063034  -0.02272478  0.06184517\n",
      "   0.03744913 -0.00751562  0.00954572  0.11016147  0.02429915 -0.00077278\n",
      "   0.01034335  0.01482726 -0.06822246 -0.05939544  0.02190411  0.03945052\n",
      "  -0.04884628 -0.00552307  0.05113245  0.0342414   0.02333902 -0.01315226\n",
      "   0.01515451 -0.03625035 -0.06819116 -0.05765338 -0.05160503  0.04113428\n",
      "  -0.0154777   0.01416995 -0.07035542  0.06165114 -0.07420117  0.09438286\n",
      "   0.00774255 -0.04791952  0.09487133  0.06020354 -0.02937498  0.05366033\n",
      "  -0.05098031 -0.06611858 -0.05001807  0.00823597 -0.03199609 -0.01229879\n",
      "  -0.05123171 -0.04651342 -0.0089915   0.02571904 -0.041391   -0.03075121\n",
      "   0.00726541 -0.01450123 -0.0364918  -0.05215725 -0.05668604  0.03704308\n",
      "   0.04149637  0.05727961  0.01213237  0.04598372  0.0333932  -0.04876644\n",
      "  -0.02562891 -0.03463634 -0.0112821  -0.00972642  0.00692945 -0.01083127\n",
      "  -0.01650919  0.04496781  0.01224945  0.07662851 -0.04536317  0.07684816\n",
      "  -0.06829893  0.00660856  0.00746848  0.03824338 -0.00540722  0.01269146\n",
      "  -0.02400788  0.01390582 -0.02301105  0.00041156 -0.01012683  0.02523189\n",
      "  -0.012092    0.02592711  0.04693777 -0.06702039 -0.03724068 -0.04823183\n",
      "   0.04843681  0.01038774 -0.06336087 -0.0156668   0.04168632  0.00917922\n",
      "  -0.02069708 -0.0247115  -0.06107789 -0.00436255 -0.02700658 -0.02981561\n",
      "   0.02864637 -0.0449001   0.02461612 -0.00396248 -0.06094465  0.07641841\n",
      "  -0.01410442 -0.0253572   0.06064675  0.06061034 -0.06539125  0.0187633\n",
      "  -0.02146232 -0.08089294 -0.09690257 -0.02740385 -0.02020344  0.05780921\n",
      "  -0.05540393  0.05510009 -0.03332917 -0.07841402 -0.07878609  0.01146194\n",
      "   0.04123399 -0.05211356 -0.0582474  -0.06592244 -0.01313032  0.02678393\n",
      "  -0.05343274  0.00440662  0.053574   -0.0561483   0.02102838  0.03821297\n",
      "   0.02915834  0.00747701 -0.03651261 -0.01624576 -0.07474233  0.00650053\n",
      "   0.117842    0.02729447 -0.03053163  0.05341165  0.04454866  0.03931216\n",
      "   0.09956812  0.02452448  0.00883975  0.07133874  0.02985579 -0.03707941\n",
      "  -0.0434027   0.03549205  0.02058476  0.03808713  0.03933963  0.06698063\n",
      "   0.02990459 -0.01204948  0.00339209 -0.00960551  0.03788317  0.07059729\n",
      "  -0.01144606  0.01229244  0.08274607 -0.00732027 -0.05824679  0.10356169\n",
      "  -0.0094143   0.01588267  0.00167197  0.03159037  0.02479352 -0.01597543\n",
      "   0.03313017 -0.11997186  0.03024802 -0.01534616  0.00127044  0.06609464\n",
      "   0.02183471 -0.03870533 -0.01355305  0.0196354   0.05471844  0.03522392\n",
      "   0.00202838 -0.02855081 -0.0436471   0.01689846  0.03851288  0.01119246\n",
      "  -0.08929126 -0.01628174  0.01371785  0.02353508 -0.04625374  0.02600716\n",
      "   0.01393424  0.05441526  0.00615437 -0.02123166 -0.02383309  0.03009527\n",
      "   0.03507154 -0.08470742  0.07524072 -0.04900159 -0.03824297  0.02005625\n",
      "  -0.04827765 -0.03476966 -0.05669461  0.07462248  0.02860466 -0.03397477\n",
      "   0.02375467  0.0010452   0.00727962 -0.03291095  0.04327936 -0.04631392\n",
      "  -0.03558316 -0.02410508  0.06120874 -0.05615826 -0.08075131 -0.0137067\n",
      "  -0.00044124 -0.08104508  0.08530852 -0.07473116 -0.02352187  0.03188273\n",
      "  -0.01602949  0.02607873  0.03390785 -0.02008476 -0.02975241 -0.0302441\n",
      "  -0.07765332  0.00190004  0.0306004  -0.03319408 -0.02808125 -0.02818995\n",
      "  -0.07130712 -0.02210228 -0.06517854  0.01152103  0.04455154 -0.00785413\n",
      "  -0.01375183  0.03922431 -0.00474037  0.01261893  0.05405952 -0.05730643\n",
      "  -0.02695682  0.01536124 -0.00086421  0.01635651 -0.06255824 -0.03794855\n",
      "   0.03875137 -0.00511006  0.09627219 -0.02878522 -0.02432816 -0.08068776\n",
      "  -0.00526082 -0.0458064   0.01031234 -0.02698353 -0.06881353 -0.03558536\n",
      "   0.03405454 -0.09444208  0.00567452 -0.02744342  0.03458241 -0.03737978\n",
      "  -0.04397875  0.02560822  0.00722427 -0.01386164  0.03910863 -0.07955288\n",
      "   0.03376446  0.0303402  -0.02526729  0.06460379  0.06017378  0.02656833\n",
      "   0.000491    0.03874032  0.06629907 -0.07098213  0.04496467 -0.01898149\n",
      "   0.06656215 -0.0067992   0.01262479  0.03711055 -0.01604308 -0.04118203\n",
      "  -0.05387774 -0.0363503  -0.01390218 -0.0137256   0.02476459  0.05006815\n",
      "  -0.02730579 -0.01190232  0.0706568   0.01404586  0.01984414 -0.05409718\n",
      "  -0.02737833 -0.09573251 -0.02532179 -0.00193205  0.01844274 -0.04268635\n",
      "   0.06987672 -0.04131944  0.00438592  0.02850924  0.08211428 -0.03913155\n",
      "   0.00264381 -0.12220404 -0.0224926   0.059965   -0.03115409  0.07936425\n",
      "   0.01741082  0.02059508 -0.02845884  0.00627551  0.01968188 -0.02061144\n",
      "   0.01399168  0.00455417 -0.01095931 -0.02148769 -0.05967702 -0.07111817\n",
      "   0.05957249  0.01643533 -0.07622371 -0.07805865  0.0049861  -0.0179853\n",
      "  -0.07184526 -0.05129252 -0.07481048  0.00494767 -0.04115682  0.00959976\n",
      "   0.02060041  0.0539535   0.04293294  0.0162659   0.0809947  -0.03331964\n",
      "  -0.0117103   0.02815461 -0.08322152 -0.01593661  0.06004281  0.06888754\n",
      "   0.03986826 -0.05247298  0.02286522  0.04605852  0.01214583 -0.01620888\n",
      "   0.04491688  0.05243057 -0.06609563 -0.02674789 -0.06574447 -0.02983483\n",
      "  -0.03286179 -0.0341695  -0.0127625  -0.03432469 -0.03980097 -0.0369922\n",
      "   0.01653328 -0.02075193  0.02116952  0.03323997 -0.04755267 -0.00554903\n",
      "   0.05113972  0.02292646  0.03295898 -0.06207736  0.07380884 -0.06839673\n",
      "   0.06278647 -0.00615144  0.03377312 -0.05659176 -0.00696464  0.0442487\n",
      "  -0.01600138 -0.04408437  0.01939425 -0.0040339   0.01576127  0.03264733\n",
      "  -0.03385737 -0.03255405 -0.02746593  0.05273899  0.01850544  0.04152621\n",
      "  -0.06056116  0.00188016 -0.05293378  0.02977061  0.01565065  0.02585942\n",
      "  -0.01079602 -0.0251943  -0.04747934  0.00228073  0.06186875  0.05837283\n",
      "   0.00334668 -0.01386614 -0.00626584 -0.0074322   0.09155073  0.04740443\n",
      "  -0.02826038 -0.03493985  0.02874506 -0.00297582  0.08044478  0.08776549\n",
      "   0.01951958  0.07297342  0.06428444 -0.02805423 -0.02069601 -0.02491912\n",
      "   0.01416174  0.01735874  0.02523534  0.01916438  0.03095045  0.01848352\n",
      "  -0.06285969 -0.03973932  0.10712719 -0.06443982  0.00570433 -0.00882013\n",
      "  -0.01421769  0.03016425  0.08171633  0.03410171 -0.07964829 -0.06510738\n",
      "  -0.02805409  0.08474384  0.02522042  0.06854501 -0.00523394 -0.03939554\n",
      "   0.01020869  0.00400388]], shape=(1, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_goldenretriever(encoder=USEEncoder, save_dir=\"./finetune_use\", kbs=kbs,\n",
    "                     query_string=query_string, kb_name=\"nrf_virement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer and optimizer\n",
      "model initiated!\n",
      "cost_mean_batch 0.009000003\n",
      "Initializing tokenizer and optimizer\n",
      "model initiated!\n",
      "2020-05-14 20:42:28.124809 : kb loaded - nrf_virement \n",
      "encoded_text tf.Tensor(\n",
      "[[-0.13788912  0.17447492 -0.893247   ...  0.65187836 -0.10483229\n",
      "  -0.09538179]\n",
      " [-0.13961184  0.17658634 -0.89331156 ...  0.6524843  -0.10137887\n",
      "  -0.09767119]\n",
      " [ 0.46738753 -0.5955453   0.626259   ... -0.1343245  -0.9994972\n",
      "   0.6047143 ]\n",
      " ...\n",
      " [-0.12754634  0.17121354 -0.9021557  ...  0.6586172  -0.14886823\n",
      "  -0.09163377]\n",
      " [-0.21566625  0.0611416   0.3675295  ... -0.18863773 -0.99876195\n",
      "   0.04262691]\n",
      " [ 0.4591443  -0.4570454   0.67921865 ... -0.40107793 -0.99924856\n",
      "   0.5520427 ]], shape=(20, 768), dtype=float32)\n",
      "encoded_text_2 tf.Tensor(\n",
      "[[-0.13788912  0.17447492 -0.893247   ...  0.65187836 -0.10483229\n",
      "  -0.09538179]\n",
      " [-0.13961184  0.17658634 -0.89331156 ...  0.6524843  -0.10137887\n",
      "  -0.09767119]\n",
      " [ 0.46738753 -0.5955453   0.626259   ... -0.1343245  -0.9994972\n",
      "   0.6047143 ]\n",
      " ...\n",
      " [-0.12754634  0.17121354 -0.9021557  ...  0.6586172  -0.14886823\n",
      "  -0.09163377]\n",
      " [-0.21566625  0.0611416   0.3675295  ... -0.18863773 -0.99876195\n",
      "   0.04262691]\n",
      " [ 0.4591443  -0.4570454   0.67921865 ... -0.40107793 -0.99924856\n",
      "   0.5520427 ]], shape=(20, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_goldenretriever(encoder=ALBERTEncoder, save_dir=\"./finetune_ab\", kbs=kbs,\n",
    "                     query_string=query_string, kb_name=\"nrf_virement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\Kenneth\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model from Hub, initializing tokenizer and optimizer\n",
      "model initiated!\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_mean_batch 0.009000003\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x000001F75C17D1E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenneth\\Anaconda3\\envs\\goldenre_fastapi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_b\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetune_b\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model from Hub, initializing tokenizer and optimizer\n",
      "model initiated!\n",
      "model initiated!\n",
      "2020-05-14 20:12:58.293952 : kb loaded - nrf_virement \n",
      "encoded_text tf.Tensor(\n",
      "[[-0.9291435  -0.27677286 -0.4453595   0.7965723   0.12668778 -0.14410233\n",
      "   0.9025326   0.31802318 -0.34721842 -0.9999503  -0.01584115  0.8066995\n",
      "   0.98737043  0.15799586  0.95072967 -0.6912116  -0.31104967 -0.65116733\n",
      "   0.22260383 -0.7609941   0.63196707  0.99704844  0.33729225  0.23478359\n",
      "   0.42206326  0.8977543  -0.7308328   0.950486    0.9629009   0.7482801\n",
      "  -0.72387433  0.13606414 -0.9907128  -0.10589422 -0.48667514 -0.9899922\n",
      "   0.26835898 -0.7442552   0.07682539  0.1357647  -0.8997477   0.1150761\n",
      "   0.99973905 -0.4107975   0.12698889 -0.28491598 -0.9999993   0.26945782\n",
      "  -0.9156161   0.56834775  0.44929972  0.18698466  0.10193743  0.41794595\n",
      "   0.41930962  0.142543   -0.0940474   0.06745354 -0.18820778 -0.543353\n",
      "  -0.59150755  0.4353783  -0.5030982  -0.89181125  0.53510845  0.2544465\n",
      "   0.01428961 -0.18039016  0.00988009 -0.15261503  0.89425063  0.15257081\n",
      "   0.1706718  -0.8205736   0.21068187  0.17372622 -0.59648746  1.\n",
      "  -0.62286866 -0.9821857   0.25494662  0.34585953  0.5029586   0.23466644\n",
      "  -0.09899789 -1.          0.39503658 -0.03501711 -0.9921921   0.16598612\n",
      "   0.34971753 -0.13100101  0.04294905  0.44910812 -0.3682596  -0.18312149\n",
      "  -0.20669326 -0.4543329  -0.10197742 -0.04434017 -0.05464809 -0.19777189\n",
      "  -0.24302341 -0.2867981   0.21850534 -0.4245832  -0.66592306  0.34155327\n",
      "  -0.22448428  0.6806142   0.3880357  -0.2293524   0.36081696 -0.9581543\n",
      "   0.60230786 -0.31627336 -0.9886968  -0.5007434  -0.98984414  0.6085501\n",
      "  -0.06305928 -0.10979065  0.9686958   0.2770845   0.34827933 -0.07909229\n",
      "  -0.5822565  -1.         -0.46118954 -0.36042598  0.01200216 -0.14635867\n",
      "  -0.98400265 -0.96092886  0.6156969   0.957684    0.1374181   0.9994227\n",
      "  -0.21361816  0.9530045   0.0114987  -0.36498067  0.19044232 -0.39225847\n",
      "   0.5090831   0.20540087 -0.75049096  0.14040953 -0.0797045   0.16544518\n",
      "  -0.40914765 -0.17219448 -0.24240908 -0.94031006 -0.32929447  0.9569965\n",
      "  -0.17418143 -0.55892956  0.410445   -0.2523837  -0.38398832  0.8365921\n",
      "   0.44841275  0.34077504 -0.3477558   0.3969527  -0.13727544  0.47467026\n",
      "  -0.88312835  0.23373024  0.40171254 -0.24675632 -0.39128247 -0.98012\n",
      "  -0.24564233  0.44973904  0.9914683   0.8223966   0.23904389  0.4710264\n",
      "  -0.14784318  0.44477284 -0.96743417  0.98295057 -0.09778931  0.2498602\n",
      "   0.45491362  0.16729656 -0.8778442  -0.2737102   0.8093801  -0.3131278\n",
      "  -0.8610407   0.01114511 -0.3822615  -0.3893459  -0.33235303  0.51783854\n",
      "  -0.24010871 -0.27491283  0.11029459  0.9345151   0.9722671   0.7822452\n",
      "  -0.33401245  0.6138893  -0.89787966 -0.55014545  0.09600458  0.14487211\n",
      "   0.04418523  0.9953119  -0.13713476 -0.08518426 -0.9433226  -0.98588103\n",
      "  -0.08772038 -0.92466044  0.00905161 -0.58553785  0.47751954  0.58857805\n",
      "   0.08066601  0.44990388 -0.98873514 -0.8285662   0.36783397 -0.32636175\n",
      "   0.39525014 -0.25994724  0.52549064  0.6649201  -0.63835317  0.83467245\n",
      "   0.8985993  -0.39501485 -0.6954      0.85440814 -0.22127281  0.89436424\n",
      "  -0.56189114  0.9815149   0.52754277  0.6141772  -0.9373282  -0.3036006\n",
      "  -0.9043318  -0.3204373   0.0600108  -0.3143586   0.5786169   0.49062365\n",
      "   0.31916353  0.6956906  -0.585609    0.9983152  -0.6665199  -0.9674207\n",
      "   0.48705563 -0.18393189 -0.98962635  0.57167447  0.23208788 -0.40779945\n",
      "  -0.37777647 -0.65027565 -0.973407    0.88599837  0.05645388  0.9906968\n",
      "   0.07320417 -0.93421733 -0.55649984 -0.93495035 -0.27389652 -0.0784994\n",
      "   0.2673566  -0.17980006 -0.9687877   0.5018024   0.5852754   0.44303885\n",
      "  -0.32866946  0.99868345  0.99997896  0.9755983   0.90624154  0.9164177\n",
      "  -0.99218976 -0.35050017  0.9999819  -0.93929785 -0.99999976 -0.9455696\n",
      "  -0.504812    0.34804294 -1.         -0.23189901  0.09490982 -0.92064726\n",
      "   0.19179772  0.9826277   0.9935742  -1.          0.85812545  0.95230716\n",
      "  -0.56149167  0.8254394  -0.25268954  0.97886455  0.48122013  0.32263878\n",
      "  -0.15814206  0.31634468 -0.6415385  -0.85589314 -0.09821205 -0.32688016\n",
      "   0.9237949   0.11532426 -0.78576237 -0.9158088   0.04051819 -0.11910424\n",
      "  -0.47239006 -0.9640279  -0.05182699  0.12122067  0.6740661   0.09066068\n",
      "   0.27606276 -0.74981654  0.12845618 -0.49840018  0.28364336  0.6520129\n",
      "  -0.9418647  -0.6099824   0.32816538 -0.382612   -0.1450197  -0.95878154\n",
      "   0.9675749  -0.3329291   0.4947459   1.         -0.04354282 -0.89239186\n",
      "   0.38349184  0.19460826  0.03384933  1.          0.73071396 -0.9823545\n",
      "  -0.48871228  0.5530477  -0.4949458  -0.5383991   0.99888045 -0.14721555\n",
      "  -0.08550607  0.02748795  0.97933465 -0.9923834   0.89967716 -0.94177586\n",
      "  -0.9686748   0.9670607   0.9525785  -0.4840567  -0.6166413   0.08410973\n",
      "  -0.35203648  0.19803669 -0.9717329   0.6486929   0.464048   -0.06168247\n",
      "   0.90312505 -0.8840998  -0.4612267   0.3116746  -0.3480095   0.25961864\n",
      "   0.6551171   0.45665622 -0.20070769  0.05908529 -0.19458887 -0.23782642\n",
      "  -0.9815787  -0.02271263  1.         -0.07235011  0.11061791 -0.342704\n",
      "   0.06325271 -0.33603537  0.45411402  0.44582692 -0.25110722 -0.8305477\n",
      "   0.42899904 -0.9651517  -0.9890132   0.7727109   0.09064393 -0.32711127\n",
      "   0.99994975  0.26527902  0.14178574  0.10187706  0.85353315 -0.06182425\n",
      "   0.48410973  0.36402696  0.9877279  -0.20568249  0.46749192  0.88519347\n",
      "  -0.57684326 -0.29906103 -0.64718187 -0.11454949 -0.9232878   0.13389128\n",
      "  -0.9664749   0.9710694   0.60939735  0.27445686  0.16450752  0.09593814\n",
      "   1.          0.04150704  0.5802969  -0.50830334  0.8525682  -0.9899666\n",
      "  -0.8692925  -0.35300276 -0.0121095  -0.3513502  -0.20583211  0.23083384\n",
      "  -0.9760606   0.25865626  0.28384396 -0.9881669  -0.9926849   0.21376406\n",
      "   0.8028562   0.06607424 -0.84640884 -0.6782788  -0.63035405  0.3522488\n",
      "  -0.1969256  -0.9496008   0.3105982  -0.23866399  0.4038941  -0.16193932\n",
      "   0.48878232  0.27028236  0.80943614  0.32082868  0.11202839  0.02094311\n",
      "  -0.80315244  0.84124804 -0.866378   -0.5297327  -0.14657287  1.\n",
      "  -0.59753555  0.5145529   0.7979551   0.7713294  -0.03856137  0.22715311\n",
      "   0.612184    0.23909874 -0.34740108 -0.35802478 -0.7200966  -0.3266377\n",
      "   0.68057746 -0.19810629  0.18875843  0.78457624  0.25228998  0.06556392\n",
      "   0.06542517 -0.0410848   0.9995522  -0.16059768 -0.01656998 -0.4176919\n",
      "   0.0339134  -0.29276273 -0.45702678  0.9999998   0.27043816 -0.05512843\n",
      "  -0.9922017  -0.39276809 -0.926603    0.99990445  0.8419396  -0.76031816\n",
      "   0.67368495  0.513168   -0.10300484  0.8036154  -0.11422077 -0.17361243\n",
      "   0.2509767   0.01906766  0.9649524  -0.43020657 -0.97389776 -0.474133\n",
      "   0.35101864 -0.9690056   0.99329764 -0.49138388 -0.23558737 -0.3668581\n",
      "   0.16266017  0.61558473 -0.16259521 -0.987589   -0.15538973  0.07704336\n",
      "   0.96749586  0.1952295  -0.54218566 -0.9320737   0.26450554  0.3062385\n",
      "  -0.6032785  -0.9208443   0.9757214  -0.9860111   0.5853806   0.9999999\n",
      "   0.30047587 -0.50170994  0.03533394 -0.511734    0.18872106  0.06287289\n",
      "   0.6879981  -0.9594425  -0.21872813 -0.09313312  0.15610951 -0.10011392\n",
      "   0.08064688  0.70126     0.11904953 -0.47078034 -0.5376898  -0.03668628\n",
      "   0.40367484  0.8431691  -0.1735235  -0.10189903  0.11891127 -0.14832604\n",
      "  -0.93430233 -0.28419593 -0.32288355 -0.9990031   0.7318473  -1.\n",
      "  -0.055354   -0.28312317 -0.22554624  0.8711757   0.16876374  0.2568523\n",
      "  -0.7900896  -0.38715142  0.6580589   0.75032264 -0.14061147 -0.09060843\n",
      "  -0.7934866   0.10799585  0.02755111  0.11655539 -0.24554284  0.7588891\n",
      "  -0.18416622  1.          0.03332463 -0.62295926 -0.97978896  0.14029473\n",
      "  -0.16569576  0.9999962  -0.94684607 -0.95936817  0.36000425 -0.5335256\n",
      "  -0.84745127  0.19738458  0.02058289 -0.5828317  -0.58724296  0.96472067\n",
      "   0.8653482  -0.5418946   0.32565218 -0.2702213  -0.42399898 -0.10484183\n",
      "   0.2506313   0.9887333   0.11722032  0.9492823   0.57671726  0.12820993\n",
      "   0.97341406  0.26220688  0.6576924   0.04364165  0.99999994  0.28029135\n",
      "  -0.91504     0.3646513  -0.98875594 -0.1055079  -0.96435153  0.2416144\n",
      "   0.12404368  0.9197515  -0.07560136  0.9720822  -0.08258288  0.00690727\n",
      "  -0.41655245  0.1888843   0.3993479  -0.93263227 -0.9875608  -0.988884\n",
      "   0.43700197 -0.40931833  0.0051091   0.20629935  0.16900064  0.35554692\n",
      "   0.3765409  -0.9999999   0.9475715   0.34273085  0.5855943   0.97055924\n",
      "   0.44630992  0.37971652  0.1755895  -0.9909696  -0.97806674 -0.2808554\n",
      "  -0.19383782  0.7637208   0.6821423   0.9156615   0.3846585  -0.4754394\n",
      "  -0.10263035  0.07013651 -0.4369463  -0.99471116  0.31440166 -0.14314544\n",
      "  -0.97709805  0.96635157 -0.40780556 -0.07862025  0.38134173 -0.48064694\n",
      "   0.9503056   0.69841707  0.40119007  0.10402679  0.4789479   0.90050465\n",
      "   0.9541153   0.98801315 -0.4215413   0.7985305  -0.23350798  0.41749993\n",
      "   0.49254698 -0.937539    0.06798112  0.11582888 -0.3230098   0.23231237\n",
      "  -0.14393544 -0.9804112   0.35044974 -0.24958849  0.48984465 -0.33226815\n",
      "   0.10912374 -0.31288606 -0.19370224 -0.68394756 -0.55492485  0.5670118\n",
      "   0.44805604  0.91625726  0.51054794  0.0655631  -0.64089495 -0.12675609\n",
      "  -0.28640312 -0.909444    0.9402277  -0.0170027   0.09256793  0.12197443\n",
      "  -0.09209298  0.5312278  -0.21280815 -0.38681528 -0.30135903 -0.79193026\n",
      "   0.8571286  -0.33046967 -0.46799958 -0.5406761   0.6590151   0.2916096\n",
      "   0.99812555 -0.34417102 -0.5267488  -0.2299644  -0.24227402  0.32614896\n",
      "  -0.43772924 -0.9999999   0.41374892  0.05353912  0.3124412  -0.23837294\n",
      "   0.4572296  -0.3247415  -0.97783107 -0.0933369   0.0157253   0.22283292\n",
      "  -0.39104748 -0.45461518  0.51809275  0.20901676  0.82703614  0.89188534\n",
      "  -0.1094828   0.57569814  0.6102384  -0.22288516 -0.6934098   0.9413666 ]], shape=(1, 768), dtype=float32)\n",
      "encoded_text_2 tf.Tensor(\n",
      "[[-0.9291435  -0.27677286 -0.4453595   0.7965723   0.12668778 -0.14410233\n",
      "   0.9025326   0.31802318 -0.34721842 -0.9999503  -0.01584115  0.8066995\n",
      "   0.98737043  0.15799586  0.95072967 -0.6912116  -0.31104967 -0.65116733\n",
      "   0.22260383 -0.7609941   0.63196707  0.99704844  0.33729225  0.23478359\n",
      "   0.42206326  0.8977543  -0.7308328   0.950486    0.9629009   0.7482801\n",
      "  -0.72387433  0.13606414 -0.9907128  -0.10589422 -0.48667514 -0.9899922\n",
      "   0.26835898 -0.7442552   0.07682539  0.1357647  -0.8997477   0.1150761\n",
      "   0.99973905 -0.4107975   0.12698889 -0.28491598 -0.9999993   0.26945782\n",
      "  -0.9156161   0.56834775  0.44929972  0.18698466  0.10193743  0.41794595\n",
      "   0.41930962  0.142543   -0.0940474   0.06745354 -0.18820778 -0.543353\n",
      "  -0.59150755  0.4353783  -0.5030982  -0.89181125  0.53510845  0.2544465\n",
      "   0.01428961 -0.18039016  0.00988009 -0.15261503  0.89425063  0.15257081\n",
      "   0.1706718  -0.8205736   0.21068187  0.17372622 -0.59648746  1.\n",
      "  -0.62286866 -0.9821857   0.25494662  0.34585953  0.5029586   0.23466644\n",
      "  -0.09899789 -1.          0.39503658 -0.03501711 -0.9921921   0.16598612\n",
      "   0.34971753 -0.13100101  0.04294905  0.44910812 -0.3682596  -0.18312149\n",
      "  -0.20669326 -0.4543329  -0.10197742 -0.04434017 -0.05464809 -0.19777189\n",
      "  -0.24302341 -0.2867981   0.21850534 -0.4245832  -0.66592306  0.34155327\n",
      "  -0.22448428  0.6806142   0.3880357  -0.2293524   0.36081696 -0.9581543\n",
      "   0.60230786 -0.31627336 -0.9886968  -0.5007434  -0.98984414  0.6085501\n",
      "  -0.06305928 -0.10979065  0.9686958   0.2770845   0.34827933 -0.07909229\n",
      "  -0.5822565  -1.         -0.46118954 -0.36042598  0.01200216 -0.14635867\n",
      "  -0.98400265 -0.96092886  0.6156969   0.957684    0.1374181   0.9994227\n",
      "  -0.21361816  0.9530045   0.0114987  -0.36498067  0.19044232 -0.39225847\n",
      "   0.5090831   0.20540087 -0.75049096  0.14040953 -0.0797045   0.16544518\n",
      "  -0.40914765 -0.17219448 -0.24240908 -0.94031006 -0.32929447  0.9569965\n",
      "  -0.17418143 -0.55892956  0.410445   -0.2523837  -0.38398832  0.8365921\n",
      "   0.44841275  0.34077504 -0.3477558   0.3969527  -0.13727544  0.47467026\n",
      "  -0.88312835  0.23373024  0.40171254 -0.24675632 -0.39128247 -0.98012\n",
      "  -0.24564233  0.44973904  0.9914683   0.8223966   0.23904389  0.4710264\n",
      "  -0.14784318  0.44477284 -0.96743417  0.98295057 -0.09778931  0.2498602\n",
      "   0.45491362  0.16729656 -0.8778442  -0.2737102   0.8093801  -0.3131278\n",
      "  -0.8610407   0.01114511 -0.3822615  -0.3893459  -0.33235303  0.51783854\n",
      "  -0.24010871 -0.27491283  0.11029459  0.9345151   0.9722671   0.7822452\n",
      "  -0.33401245  0.6138893  -0.89787966 -0.55014545  0.09600458  0.14487211\n",
      "   0.04418523  0.9953119  -0.13713476 -0.08518426 -0.9433226  -0.98588103\n",
      "  -0.08772038 -0.92466044  0.00905161 -0.58553785  0.47751954  0.58857805\n",
      "   0.08066601  0.44990388 -0.98873514 -0.8285662   0.36783397 -0.32636175\n",
      "   0.39525014 -0.25994724  0.52549064  0.6649201  -0.63835317  0.83467245\n",
      "   0.8985993  -0.39501485 -0.6954      0.85440814 -0.22127281  0.89436424\n",
      "  -0.56189114  0.9815149   0.52754277  0.6141772  -0.9373282  -0.3036006\n",
      "  -0.9043318  -0.3204373   0.0600108  -0.3143586   0.5786169   0.49062365\n",
      "   0.31916353  0.6956906  -0.585609    0.9983152  -0.6665199  -0.9674207\n",
      "   0.48705563 -0.18393189 -0.98962635  0.57167447  0.23208788 -0.40779945\n",
      "  -0.37777647 -0.65027565 -0.973407    0.88599837  0.05645388  0.9906968\n",
      "   0.07320417 -0.93421733 -0.55649984 -0.93495035 -0.27389652 -0.0784994\n",
      "   0.2673566  -0.17980006 -0.9687877   0.5018024   0.5852754   0.44303885\n",
      "  -0.32866946  0.99868345  0.99997896  0.9755983   0.90624154  0.9164177\n",
      "  -0.99218976 -0.35050017  0.9999819  -0.93929785 -0.99999976 -0.9455696\n",
      "  -0.504812    0.34804294 -1.         -0.23189901  0.09490982 -0.92064726\n",
      "   0.19179772  0.9826277   0.9935742  -1.          0.85812545  0.95230716\n",
      "  -0.56149167  0.8254394  -0.25268954  0.97886455  0.48122013  0.32263878\n",
      "  -0.15814206  0.31634468 -0.6415385  -0.85589314 -0.09821205 -0.32688016\n",
      "   0.9237949   0.11532426 -0.78576237 -0.9158088   0.04051819 -0.11910424\n",
      "  -0.47239006 -0.9640279  -0.05182699  0.12122067  0.6740661   0.09066068\n",
      "   0.27606276 -0.74981654  0.12845618 -0.49840018  0.28364336  0.6520129\n",
      "  -0.9418647  -0.6099824   0.32816538 -0.382612   -0.1450197  -0.95878154\n",
      "   0.9675749  -0.3329291   0.4947459   1.         -0.04354282 -0.89239186\n",
      "   0.38349184  0.19460826  0.03384933  1.          0.73071396 -0.9823545\n",
      "  -0.48871228  0.5530477  -0.4949458  -0.5383991   0.99888045 -0.14721555\n",
      "  -0.08550607  0.02748795  0.97933465 -0.9923834   0.89967716 -0.94177586\n",
      "  -0.9686748   0.9670607   0.9525785  -0.4840567  -0.6166413   0.08410973\n",
      "  -0.35203648  0.19803669 -0.9717329   0.6486929   0.464048   -0.06168247\n",
      "   0.90312505 -0.8840998  -0.4612267   0.3116746  -0.3480095   0.25961864\n",
      "   0.6551171   0.45665622 -0.20070769  0.05908529 -0.19458887 -0.23782642\n",
      "  -0.9815787  -0.02271263  1.         -0.07235011  0.11061791 -0.342704\n",
      "   0.06325271 -0.33603537  0.45411402  0.44582692 -0.25110722 -0.8305477\n",
      "   0.42899904 -0.9651517  -0.9890132   0.7727109   0.09064393 -0.32711127\n",
      "   0.99994975  0.26527902  0.14178574  0.10187706  0.85353315 -0.06182425\n",
      "   0.48410973  0.36402696  0.9877279  -0.20568249  0.46749192  0.88519347\n",
      "  -0.57684326 -0.29906103 -0.64718187 -0.11454949 -0.9232878   0.13389128\n",
      "  -0.9664749   0.9710694   0.60939735  0.27445686  0.16450752  0.09593814\n",
      "   1.          0.04150704  0.5802969  -0.50830334  0.8525682  -0.9899666\n",
      "  -0.8692925  -0.35300276 -0.0121095  -0.3513502  -0.20583211  0.23083384\n",
      "  -0.9760606   0.25865626  0.28384396 -0.9881669  -0.9926849   0.21376406\n",
      "   0.8028562   0.06607424 -0.84640884 -0.6782788  -0.63035405  0.3522488\n",
      "  -0.1969256  -0.9496008   0.3105982  -0.23866399  0.4038941  -0.16193932\n",
      "   0.48878232  0.27028236  0.80943614  0.32082868  0.11202839  0.02094311\n",
      "  -0.80315244  0.84124804 -0.866378   -0.5297327  -0.14657287  1.\n",
      "  -0.59753555  0.5145529   0.7979551   0.7713294  -0.03856137  0.22715311\n",
      "   0.612184    0.23909874 -0.34740108 -0.35802478 -0.7200966  -0.3266377\n",
      "   0.68057746 -0.19810629  0.18875843  0.78457624  0.25228998  0.06556392\n",
      "   0.06542517 -0.0410848   0.9995522  -0.16059768 -0.01656998 -0.4176919\n",
      "   0.0339134  -0.29276273 -0.45702678  0.9999998   0.27043816 -0.05512843\n",
      "  -0.9922017  -0.39276809 -0.926603    0.99990445  0.8419396  -0.76031816\n",
      "   0.67368495  0.513168   -0.10300484  0.8036154  -0.11422077 -0.17361243\n",
      "   0.2509767   0.01906766  0.9649524  -0.43020657 -0.97389776 -0.474133\n",
      "   0.35101864 -0.9690056   0.99329764 -0.49138388 -0.23558737 -0.3668581\n",
      "   0.16266017  0.61558473 -0.16259521 -0.987589   -0.15538973  0.07704336\n",
      "   0.96749586  0.1952295  -0.54218566 -0.9320737   0.26450554  0.3062385\n",
      "  -0.6032785  -0.9208443   0.9757214  -0.9860111   0.5853806   0.9999999\n",
      "   0.30047587 -0.50170994  0.03533394 -0.511734    0.18872106  0.06287289\n",
      "   0.6879981  -0.9594425  -0.21872813 -0.09313312  0.15610951 -0.10011392\n",
      "   0.08064688  0.70126     0.11904953 -0.47078034 -0.5376898  -0.03668628\n",
      "   0.40367484  0.8431691  -0.1735235  -0.10189903  0.11891127 -0.14832604\n",
      "  -0.93430233 -0.28419593 -0.32288355 -0.9990031   0.7318473  -1.\n",
      "  -0.055354   -0.28312317 -0.22554624  0.8711757   0.16876374  0.2568523\n",
      "  -0.7900896  -0.38715142  0.6580589   0.75032264 -0.14061147 -0.09060843\n",
      "  -0.7934866   0.10799585  0.02755111  0.11655539 -0.24554284  0.7588891\n",
      "  -0.18416622  1.          0.03332463 -0.62295926 -0.97978896  0.14029473\n",
      "  -0.16569576  0.9999962  -0.94684607 -0.95936817  0.36000425 -0.5335256\n",
      "  -0.84745127  0.19738458  0.02058289 -0.5828317  -0.58724296  0.96472067\n",
      "   0.8653482  -0.5418946   0.32565218 -0.2702213  -0.42399898 -0.10484183\n",
      "   0.2506313   0.9887333   0.11722032  0.9492823   0.57671726  0.12820993\n",
      "   0.97341406  0.26220688  0.6576924   0.04364165  0.99999994  0.28029135\n",
      "  -0.91504     0.3646513  -0.98875594 -0.1055079  -0.96435153  0.2416144\n",
      "   0.12404368  0.9197515  -0.07560136  0.9720822  -0.08258288  0.00690727\n",
      "  -0.41655245  0.1888843   0.3993479  -0.93263227 -0.9875608  -0.988884\n",
      "   0.43700197 -0.40931833  0.0051091   0.20629935  0.16900064  0.35554692\n",
      "   0.3765409  -0.9999999   0.9475715   0.34273085  0.5855943   0.97055924\n",
      "   0.44630992  0.37971652  0.1755895  -0.9909696  -0.97806674 -0.2808554\n",
      "  -0.19383782  0.7637208   0.6821423   0.9156615   0.3846585  -0.4754394\n",
      "  -0.10263035  0.07013651 -0.4369463  -0.99471116  0.31440166 -0.14314544\n",
      "  -0.97709805  0.96635157 -0.40780556 -0.07862025  0.38134173 -0.48064694\n",
      "   0.9503056   0.69841707  0.40119007  0.10402679  0.4789479   0.90050465\n",
      "   0.9541153   0.98801315 -0.4215413   0.7985305  -0.23350798  0.41749993\n",
      "   0.49254698 -0.937539    0.06798112  0.11582888 -0.3230098   0.23231237\n",
      "  -0.14393544 -0.9804112   0.35044974 -0.24958849  0.48984465 -0.33226815\n",
      "   0.10912374 -0.31288606 -0.19370224 -0.68394756 -0.55492485  0.5670118\n",
      "   0.44805604  0.91625726  0.51054794  0.0655631  -0.64089495 -0.12675609\n",
      "  -0.28640312 -0.909444    0.9402277  -0.0170027   0.09256793  0.12197443\n",
      "  -0.09209298  0.5312278  -0.21280815 -0.38681528 -0.30135903 -0.79193026\n",
      "   0.8571286  -0.33046967 -0.46799958 -0.5406761   0.6590151   0.2916096\n",
      "   0.99812555 -0.34417102 -0.5267488  -0.2299644  -0.24227402  0.32614896\n",
      "  -0.43772924 -0.9999999   0.41374892  0.05353912  0.3124412  -0.23837294\n",
      "   0.4572296  -0.3247415  -0.97783107 -0.0933369   0.0157253   0.22283292\n",
      "  -0.39104748 -0.45461518  0.51809275  0.20901676  0.82703614  0.89188534\n",
      "  -0.1094828   0.57569814  0.6102384  -0.22288516 -0.6934098   0.9413666 ]], shape=(1, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_goldenretriever(encoder=BERTEncoder, save_dir=\"./finetune_b\", kbs=kbs,\n",
    "                     query_string=query_string, kb_name=\"nrf_virement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:goldenre_fastapi] *",
   "language": "python",
   "name": "conda-env-goldenre_fastapi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
